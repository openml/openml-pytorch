{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset and task - tiniest imagenet\n",
    "- An example of how to create a custom dataset and task using the OpenML API and upload it to the OpenML server.\n",
    "- Note that you must have an API key from the OpenML website to upload datasets and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "\n",
    "import openml\n",
    "from openml.datasets.functions import create_dataset\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset on OpenML\n",
    "- Instead of making our own, we obtain a subset of the ImageNet dataset from Stanford. This dataset has 200 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiny_imagenet():\n",
    "    dir_name = \"datasets\"\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "    # download the dataset\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    if not os.path.exists(f\"{dir_name}/tiny-imagenet-200.zip\"):\n",
    "        with open(f\"{dir_name}/tiny-imagenet-200.zip\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "        with zipfile.ZipFile(f\"{dir_name}/tiny-imagenet-200.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(f\"{dir_name}/\")\n",
    "    ## recusively find all the images\n",
    "    image_paths = glob.glob(f\"{dir_name}/tiny-imagenet-200/train/*/*/*.JPEG\")\n",
    "    ## remove the first part of the path\n",
    "    image_paths = [path.split(\"/\", 1)[-1] for path in image_paths]\n",
    "    ## create a dataframe with the image path and the label\n",
    "    label_func = lambda x: x.split(\"/\")[2]\n",
    "    df = pd.DataFrame(image_paths, columns=[\"image_path\"])\n",
    "    df[\"label\"] = df[\"image_path\"].apply(label_func)\n",
    "    ## encode the labels as integers\n",
    "    # df[\"Class_encoded\"] = pd.factorize(df[\"label\"])[0]\n",
    "\n",
    "    ## encode types\n",
    "    df[\"image_path\"] = df[\"image_path\"].astype(\"string\")\n",
    "    df[\"label\"] = df[\"label\"].astype(\"string\")\n",
    "\n",
    "\n",
    "    name = \"tiny-imagenet-200\"\n",
    "    attribute_names = df.columns\n",
    "    description = \"Tiny ImageNet contains 100000 images of 200 classes (500 for each class) downsized to 64 x 64 colored images. Each class has 500 training images, 50 validation images, and 50 test images. The dataset here just contains links to the images and the labels. The dataset can be downloaded from the official website ![here](http://cs231n.stanford.edu/tiny-imagenet-200.zip). /n Link to the paper - [Tiny ImageNet Classification with CNN](https://cs231n.stanford.edu/reports/2017/pdfs/930.pdf)\"\n",
    "    paper_url = \"https://cs231n.stanford.edu/reports/2017/pdfs/930.pdf\"\n",
    "    citation = (\"Wu, J., Zhang, Q., & Xu, G. (2017). Tiny imagenet challenge. Technical report.\")\n",
    "\n",
    "    tinyim = create_dataset(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        creator= \"Jiayu Wu, Qixiang Zhang, Guoxi Xu\",\n",
    "        contributor = \"Jiayu Wu, Qixiang Zhang, Guoxi Xu\",\n",
    "        collection_date = \"2017\",\n",
    "        language= \"English\",\n",
    "        licence=\"DbCL v1.0\",\n",
    "        default_target_attribute=\"label\",\n",
    "        attributes=\"auto\",\n",
    "        data=df,\n",
    "        citation=citation,\n",
    "        ignore_attribute=None\n",
    "    )\n",
    "    openml.config.apikey = ''\n",
    "    tinyim.publish()\n",
    "    print(f\"URL for dataset: {tinyim.openml_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tiny_imagenet()\n",
    "# https://www.openml.org/d/46346"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another, even tinier dataset\n",
    "- We subset the previous dataset to 20 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiniest_imagenet():\n",
    "    dir_name = \"datasets\"\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "    # download the dataset\n",
    "    url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    if not os.path.exists(f\"{dir_name}/tiny-imagenet-200.zip\"):\n",
    "        with open(f\"{dir_name}/tiny-imagenet-200.zip\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "        with zipfile.ZipFile(f\"{dir_name}/tiny-imagenet-200.zip\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(f\"{dir_name}/\")\n",
    "    ## recusively find all the images\n",
    "    image_paths = glob.glob(f\"{dir_name}/tiny-imagenet-200/train/*/*/*.JPEG\")\n",
    "    ## remove the first part of the path\n",
    "    image_paths = [path.split(\"/\", 1)[-1] for path in image_paths]\n",
    "    image_paths[-1]\n",
    "    ## create a dataframe with the image path and the label\n",
    "    label_func = lambda x: x.split(\"/\")[2]\n",
    "    df = pd.DataFrame(image_paths, columns=[\"image_path\"])\n",
    "    df[\"label\"] = df[\"image_path\"].apply(label_func)\n",
    "    ## encode types\n",
    "    df[\"image_path\"] = df[\"image_path\"].astype(\"string\")\n",
    "    df[\"label\"] = df[\"label\"].astype(\"string\")\n",
    "\n",
    "    # keep only first 20 images for each label\n",
    "    df = df.groupby(\"label\").head(20)\n",
    "\n",
    "\n",
    "    name = \"tiniest-imagenet-200\"\n",
    "    attribute_names = df.columns\n",
    "    description = \"Tiny ImageNet contains 100000 images of 200 classes (500 for each class) downsized to 64 x 64 colored images. !!! This dataset only links to 20 images per class (instead of the usual 500) and is ONLY for quickly testing a framework. !!! Each class has 500 training images, 50 validation images, and 50 test images. The dataset here just contains links to the images and the labels. The dataset can be downloaded from the official website ![here](http://cs231n.stanford.edu/tiny-imagenet-200.zip). /n Link to the paper - [Tiny ImageNet Classification with CNN](https://cs231n.stanford.edu/reports/2017/pdfs/930.pdf)\"\n",
    "    paper_url = \"https://cs231n.stanford.edu/reports/2017/pdfs/930.pdf\"\n",
    "    citation = (\"Wu, J., Zhang, Q., & Xu, G. (2017). Tiny imagenet challenge. Technical report.\")\n",
    "\n",
    "    tinyim = create_dataset(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        creator= \"Jiayu Wu, Qixiang Zhang, Guoxi Xu\",\n",
    "        contributor = \"Jiayu Wu, Qixiang Zhang, Guoxi Xu\",\n",
    "        collection_date = \"2017\",\n",
    "        language= \"English\",\n",
    "        licence=\"DbCL v1.0\",\n",
    "        default_target_attribute=\"label\",\n",
    "        attributes=\"auto\",\n",
    "        data=df,\n",
    "        citation=citation,\n",
    "        ignore_attribute=None\n",
    "    )\n",
    "    openml.config.apikey = ''\n",
    "    tinyim.publish()\n",
    "    print(f\"URL for dataset: {tinyim.openml_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL for dataset: https://www.openml.org/d/46347\n"
     ]
    }
   ],
   "source": [
    "create_tiniest_imagenet()\n",
    "# https://www.openml.org/d/46347"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create task on OpenML\n",
    "- Now to actually use the OpenML Pytorch API, we need to have a task associated with the dataset. This is how we create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_task():\n",
    "    # Define task parameters\n",
    "    task_type = openml.tasks.TaskType.SUPERVISED_CLASSIFICATION\n",
    "    dataset_id = 46347 # Obtained from the dataset creation step\n",
    "    evaluation_measure = 'predictive_accuracy'\n",
    "    target_name = 'label'\n",
    "    class_labels = list(pd.read_csv(\"datasets/tiniest_imagenet.csv\")[\"label\"].unique())\n",
    "    cost_matrix = None\n",
    "\n",
    "    # Create the task\n",
    "    new_task = openml.tasks.create_task(\n",
    "        task_type=task_type,\n",
    "        dataset_id=dataset_id, \n",
    "        estimation_procedure_id = 1,\n",
    "        evaluation_measure=evaluation_measure,\n",
    "        target_name=target_name,\n",
    "        class_labels=class_labels,\n",
    "        cost_matrix=cost_matrix\n",
    "    )\n",
    "    openml.config.apikey = ''\n",
    "    new_task.publish()\n",
    "    print(f\"URL for task: {new_task.openml_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL for task: https://www.openml.org/t/362128\n"
     ]
    }
   ],
   "source": [
    "create_task()\n",
    "# https://www.openml.org/t/362128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmlpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
