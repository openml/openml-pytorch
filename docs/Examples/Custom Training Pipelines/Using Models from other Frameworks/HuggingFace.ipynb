{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a model from HuggingFace\n",
    "- This frameworks supports training such models and storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch as op\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "op.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = op.OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(363295)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- First you need to get the model you need\n",
    "- ![image.png](hf.png)\n",
    "- Click use this model -> transformers -> get the code you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then you need to modify the model to work with the number of classes in your dataset\n",
    "- This is something you would need to do anyway if you were transfer learning on a dataset different from the one the model was trained on.\n",
    "- You can use the `model` object to access the model and modify the final layer to match the number of classes in your dataset. (note that this depends on the model you are using, and you might need to do this manually)\n",
    "  - In general, try either `model.classifier` or `model.fc` or `model.classifier[-1]` to access the final layer of the model.\n",
    "  - If this doesnt work, try printing the model and looking at the architecture to find the correct layer to modify.\n",
    "  - HF provides a \"num_labels\" parameter but this does not always work as expected, so it is better to modify the final layer manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
    "model_o = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "class TransformerCompatibility(torch.nn.Module):\n",
    "    def __init__(self, model_from_pretrained, num_classes) -> None:\n",
    "        super(TransformerCompatibility, self).__init__()\n",
    "        self.model = model_from_pretrained\n",
    "        # self.model.classifier = torch.nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "        self.model.classifier._modules['1'] = torch.nn.Linear(self.model.classifier._modules['1'].in_features, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # The ViT model expects the input to be of shape (batch_size, num_channels, height, width)\n",
    "        # Ensure the input is in the correct shape\n",
    "        if len(input.shape) == 3:\n",
    "            input = input.unsqueeze(0)\n",
    "        # Forward pass through the model\n",
    "        outputs = self.model(input)\n",
    "        # The output is a tuple, where the first element is the logits\n",
    "        logits = outputs.logits\n",
    "        return logits\n",
    "\n",
    "    \n",
    "model = TransformerCompatibility(model_o, num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "trainer = op.OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        # TestCallback,\n",
    "    ],\n",
    ")\n",
    "op.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run = op.add_experiment_info_to_run(run=run, trainer=trainer) \n",
    "run.publish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
