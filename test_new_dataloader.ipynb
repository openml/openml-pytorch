{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smukherjee/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from openml_pytorch.callbacks import TestCallback\n",
    "# openml imports\n",
    "# other imports\n",
    "# pytorch imports\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from openml_pytorch.callbacks import Recorder, AvgStatsCallback, ParamScheduler, PutDataOnDeviceCallback, TensorBoardCallback\n",
    "from openml_pytorch.callbacks.annealing import combine_scheds, sched_cos\n",
    "from openml_pytorch.callbacks.callback import Callback\n",
    "from openml_pytorch.callbacks.helper import listify\n",
    "from openml_pytorch.callbacks.training_callbacks import CancelBatchException, CancelEpochException, CancelTrainException, TestCallback\n",
    "from openml_pytorch.callbacks.training_callbacks import TrainEvalCallback\n",
    "from openml_pytorch.custom_datasets import OpenMLImageDataset, OpenMLTabularDataset\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import Trainer, DataModule\n",
    "from openml_pytorch.trainer import convert_to_rgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, List\n",
    "from typing import Optional, Any, Union\n",
    "from typing import Union\n",
    "import io\n",
    "import logging\n",
    "import netron\n",
    "import numpy as np\n",
    "import onnx\n",
    "import openml\n",
    "import openml_pytorch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "# openml.config.start_using_configuration_for_example()\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = DataModule(\n",
    "    batch_size=64, num_workers=0, target_mode=\"categorical\", transforms=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not download file from https://data.openml.org/datasets/0004/46578/dataset_46578.pq: Object at 'https://data.openml.org/datasets/0004/46578/dataset_46578.pq' does not exist.\n",
      "Failed to download parquet, fallback on ARFF.\n"
     ]
    }
   ],
   "source": [
    "dl = data_module.load_image_openml_dataset(\n",
    "    dataset_id= 46578,\n",
    "    image_dir=\"datasets\",\n",
    "    image_size=64,\n",
    "    filename_col=\"image_path\",\n",
    "    target_column=\"label\",\n",
    "    create_validation_dataset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    experiment_name=\"Tiny ImageNet, Resnet50,1 epoch\",\n",
    "    task_type= \"classification\",\n",
    "    dl=dl,\n",
    "    model=model,\n",
    "    opt=torch.optim.Adam,\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    metrics=[accuracy],\n",
    "    callbacks=[],\n",
    "    use_tensorboard=True,\n",
    "    device=torch.device(\"mps\"),\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openml.tasks.get_task(363295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = \"9cfaf2bb33bd321a7730903a45ea0a45\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openml.config:Requested to create log handlers, but they are already created.\n",
      "WARNING:openml.datasets.functions:Could not download file from https://data.openml.org/datasets/0004/46578/dataset_46578.pq: Object at 'https://data.openml.org/datasets/0004/46578/dataset_46578.pq' does not exist.\n",
      "INFO:openml.config:Going to run model ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
      ") on dataset tiniest-imagenet-200 for repeat 0 fold 0 sample 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mopenml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupload_flow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:164\u001b[0m, in \u001b[0;36mrun_model_on_task\u001b[0;34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _task\n\u001b[1;32m    162\u001b[0m task \u001b[38;5;241m=\u001b[39m get_task_and_type_conversion(task)\n\u001b[0;32m--> 164\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mrun_flow_on_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupload_flow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_flow:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run, flow\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:302\u001b[0m, in \u001b[0;36mrun_flow_on_task\u001b[0;34m(flow, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is already fitted!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This might cause inconsistency in comparison of results.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# execute the run\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_run_task_get_arffcontent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m data_content, trace, fold_evaluations, sample_evaluations \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    312\u001b[0m fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mrun_environment, time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%c\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated by run_flow_on_task\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:555\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent\u001b[0;34m(model, task, extension, add_local_measures, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Execute runs in parallel\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# assuming the same number of tasks as workers (n_jobs), the total compute time for this\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# statement will be similar to the slowest run\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# TODO(eddiebergman): Simplify this\u001b[39;00m\n\u001b[1;32m    545\u001b[0m job_rvals: \u001b[38;5;28mlist\u001b[39m[\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mtuple\u001b[39m[\n\u001b[1;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m     ],\n\u001b[1;32m    554\u001b[0m ]\n\u001b[0;32m--> 555\u001b[0m job_rvals \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_task_get_arffcontent_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_n_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjobs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# job_rvals contain the output of all the runs with one-to-one correspondence with `jobs`\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_fit, rep_no, fold_no, sample_no \u001b[38;5;129;01min\u001b[39;00m jobs:\n\u001b[1;32m    570\u001b[0m     pred_y, proba_y, test_indices, test_y, inner_trace, user_defined_measures_fold \u001b[38;5;241m=\u001b[39m job_rvals[\n\u001b[1;32m    571\u001b[0m         n_fit \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    572\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:792\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent_parallel_helper\u001b[0;34m(extension, fold_no, model, rep_no, sample_no, task, dataset_format, configuration)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(task\u001b[38;5;241m.\u001b[39mtask_type)\n\u001b[1;32m    782\u001b[0m config\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing to run model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopenml\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mget_dataset(task\u001b[38;5;241m.\u001b[39mdataset_id)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor repeat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    787\u001b[0m (\n\u001b[1;32m    788\u001b[0m     pred_y,\n\u001b[1;32m    789\u001b[0m     proba_y,\n\u001b[1;32m    790\u001b[0m     user_defined_measures_fold,\n\u001b[1;32m    791\u001b[0m     trace,\n\u001b[0;32m--> 792\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mextension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(eddiebergman): Likely should not be ignored\u001b[39;49;00m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_y, proba_y, test_indices, test_y, trace, user_defined_measures_fold\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/extension.py:1123\u001b[0m, in \u001b[0;36mPytorchExtension._run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer not set to config. Please use openml_pytorch.config.trainer = trainer to set the trainer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1119\u001b[0m     )\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# return trainer.run_model_on_fold(\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# model, task, X_train, rep_no, fold_no, y_train, X_test\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:819\u001b[0m, in \u001b[0;36mTrainer.run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# get the data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m X_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_train)\n\u001b[1;32m    821\u001b[0m X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "run = openml.runs.run_model_on_task(\n",
    "    model=trainer.model,\n",
    "    task=task,\n",
    "    seed=1,\n",
    "    add_local_measures=True,\n",
    "    upload_flow=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 5.5641 accuracy: 0.0059\n",
      "Valid - Loss: 5.4134 accuracy: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([196, 160, 196, 196, 182, 196, 196, 196, 196, 196,  63, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196,  63, 196, 196,  66, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 133, 196, 160, 196, 196, 196, 196, 196,\n",
       "         66,  66, 196, 196, 196, 160, 196, 196, 196, 196, 196, 196, 196,\n",
       "        182, 196, 182, 196, 160, 196, 196, 182, 196, 196,  92, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 182, 196, 196, 196, 196, 196, 196,\n",
       "        182, 196, 133, 196, 152,   2, 133, 196, 182, 196, 196, 196, 133,\n",
       "        196, 196, 196, 196, 196,   0, 196, 196, 160, 196, 196, 196, 196,\n",
       "        182, 196, 196, 196, 182, 196, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196,   2, 182, 196, 196, 196, 196, 196, 196, 196, 196,  18, 196,\n",
       "        160, 196, 160, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 152, 182, 196, 196, 160, 196, 196, 196, 196,   2, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 182, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196,   0, 196, 196, 182, 196, 196, 182,\n",
       "        196, 196, 182, 196, 196, 160, 133, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 196,  18, 196, 196, 196, 182,  66, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 133, 160, 196, 196, 182, 196, 196,\n",
       "        182, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,  18,\n",
       "        196, 182, 196, 182, 182, 196, 196, 196, 182, 196, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 182, 196, 196, 196, 196,\n",
       "        196, 196, 196, 160, 196, 196, 196, 196, 196, 196, 196, 196,  92,\n",
       "         92, 196, 196, 182, 196, 196, 196, 196, 196, 182, 160, 196, 196,\n",
       "        182, 196, 196, 196, 196, 152, 196, 196, 196, 160, 196, 196, 196,\n",
       "        196,  66, 196, 196,  18, 160, 145, 196, 196, 196, 196, 196, 196,\n",
       "        182, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 152, 196, 196, 196, 196,  63, 196, 152,\n",
       "        133, 196, 196, 196, 196, 196, 196, 196, 196, 196, 182, 196, 196,\n",
       "        196, 196, 182, 196, 196, 145, 196, 196, 196, 182,  92, 196, 196,\n",
       "        196, 196, 182, 196, 196, 196, 196, 145, 196, 196, 196, 196, 196,\n",
       "         66, 145, 196, 196, 196, 196, 160, 196, 196, 196, 160, 196, 196,\n",
       "        196, 196,  92, 196, 196, 182, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 130, 196, 196, 196, 196, 196, 182, 196,   2, 196,\n",
       "        196, 196, 196, 196, 196, 196, 145, 196, 196, 196, 196, 196, 196,\n",
       "        133, 196, 196, 145, 196, 196, 196, 160, 196, 196, 196, 196, 196,\n",
       "        196, 196,  92,  63, 196, 196,  92, 160, 196, 196, 196, 160, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 160,\n",
       "        196, 196, 196, 196,  63, 196, 196, 196, 182, 196, 133, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196,   2,  92, 196, 196, 196, 196,\n",
       "        196, 196, 160, 196, 182, 196, 196, 196, 196,  63, 196,  18, 196,\n",
       "        182, 196, 196, 196, 196, 182, 160, 196, 152, 196, 196, 196,  18,\n",
       "        196, 196, 196, 196, 196, 182, 133, 196, 196, 196, 133, 182, 196,\n",
       "        182, 182, 196, 196, 182, 196, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 160, 182, 196, 160, 182,\n",
       "        196, 196, 196,  18, 196, 196, 133, 196, 196, 160, 182, 196, 182,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 196, 196, 152,  66, 196,\n",
       "         18, 196, 196, 182, 196, 196, 196, 196, 196, 196, 182, 160,  18,\n",
       "         66, 196, 196, 196, 196, 160, 196, 196, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 196, 196, 196, 196, 196, 196, 160, 196,   0, 196,\n",
       "        196,  92, 196, 196,   0, 196, 196, 196, 196, 196, 196, 182, 160,\n",
       "        196, 182, 196, 160, 196, 196, 196, 196, 196, 196, 196, 196, 182,\n",
       "         66, 196, 145, 196,  18, 196, 196, 196, 196, 196, 196, 196,  63,\n",
       "        196, 196, 133, 196, 196,  66, 182, 196, 196, 196, 196, 196,   2,\n",
       "        196, 196, 196, 196, 145, 196, 196, 182, 182, 182, 196, 196, 160,\n",
       "        196, 196, 196, 196, 196,   2, 196, 196, 196, 196, 196, 196,  92,\n",
       "        196, 182, 196, 196, 196, 196,  66, 196, 196, 182, 160, 196, 182,\n",
       "        196, 196, 196, 196,  66, 196, 196, 196, 196, 196, 160, 196, 196,\n",
       "        196, 196, 196, 182,  66, 196, 182, 196,  66, 196, 196, 196, 196,\n",
       "         18, 196, 182, 196, 196,   0, 182, 182, 196, 196, 196, 196, 196,\n",
       "        196, 196, 196, 182, 160, 196, 196, 196, 160, 182, 196, 196, 196,\n",
       "        196, 196, 196, 196, 182, 182, 196, 160, 196, 182, 182, 196, 196,\n",
       "        196, 196, 196, 196, 160, 196, 133, 196, 196, 196, 182, 196, 196,\n",
       "        196, 196, 196, 196, 196, 130, 182]),\n",
       " array([[0.00774058, 0.00532978, 0.00720381, ..., 0.0040998 , 0.00582814,\n",
       "         0.00549038],\n",
       "        [0.00717206, 0.00530808, 0.00785972, ..., 0.0035471 , 0.00565971,\n",
       "         0.00562196],\n",
       "        [0.00785941, 0.00523855, 0.00708186, ..., 0.00429618, 0.00625319,\n",
       "         0.00564909],\n",
       "        ...,\n",
       "        [0.00775548, 0.00520391, 0.00716329, ..., 0.00416314, 0.00600476,\n",
       "         0.00563062],\n",
       "        [0.01293595, 0.00457878, 0.01643661, ..., 0.00182381, 0.00727788,\n",
       "         0.0034147 ],\n",
       "        [0.00781078, 0.00518911, 0.00715009, ..., 0.00420349, 0.00602183,\n",
       "         0.00558263]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run_model_on_fold(model = model, data = dl, fold = 0, task_type= \"classification\", model_classes= dl.model_classes, opt = torch.optim.Adam, loss_fn = torch.nn.CrossEntropyLoss(), metrics = [accuracy], callbacks = [], device = torch.device(\"mps\"), use_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:01:33.514283Z",
     "start_time": "2024-09-23T12:01:32.116044Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smukherjee/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModuleconvert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "# openml.config.start_using_configuration_for_example()\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:01:39.788930Z",
     "start_time": "2024-09-23T12:01:34.041129Z"
    }
   },
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not download file from https://data.openml.org/datasets/0004/46578/dataset_46578.pq: Object at 'https://data.openml.org/datasets/0004/46578/dataset_46578.pq' does not exist.\n",
      "Failed to download parquet, fallback on ARFF.\n"
     ]
    }
   ],
   "source": [
    "# Download the OpenML task for tiniest imagenet\n",
    "data_module.load_openml_dataset_from_task_id(363295)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not download file from https://data.openml.org/datasets/0004/46578/dataset_46578.pq: Object at 'https://data.openml.org/datasets/0004/46578/dataset_46578.pq' does not exist.\n",
      "                                     \r"
     ]
    },
    {
     "ename": "PyOpenMLError",
     "evalue": "'str' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:556\u001b[0m, in \u001b[0;36mOpenMLTrainerModule.run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     data, model_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;66;03m# typically happens when training a regressor8 on classification task\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:703\u001b[0m, in \u001b[0;36mOpenMLTrainerModule.run_training\u001b[0;34m(self, task, X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 703\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:403\u001b[0m, in \u001b[0;36mModelRunner.fit\u001b[0;34m(self, epochs, learn)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:389\u001b[0m, in \u001b[0;36mModelRunner.all_batches\u001b[0;34m(self, dl)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/custom_datasets/image_dataset.py:34\u001b[0m, in \u001b[0;36mOpenMLImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 34\u001b[0m     img_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[idx, \u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     35\u001b[0m     image \u001b[38;5;241m=\u001b[39m read_image(img_name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'iloc'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPyOpenMLError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m OpenMLTrainerModule(\n\u001b[1;32m      2\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiny ImageNet, Resnet50,1 epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     data_module\u001b[38;5;241m=\u001b[39mdata_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m openml_pytorch\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 13\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mopenml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:164\u001b[0m, in \u001b[0;36mrun_model_on_task\u001b[0;34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _task\n\u001b[1;32m    162\u001b[0m task \u001b[38;5;241m=\u001b[39m get_task_and_type_conversion(task)\n\u001b[0;32m--> 164\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mrun_flow_on_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupload_flow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_flow:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run, flow\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:302\u001b[0m, in \u001b[0;36mrun_flow_on_task\u001b[0;34m(flow, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is already fitted!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This might cause inconsistency in comparison of results.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# execute the run\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_run_task_get_arffcontent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m data_content, trace, fold_evaluations, sample_evaluations \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    312\u001b[0m fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mrun_environment, time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%c\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated by run_flow_on_task\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:555\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent\u001b[0;34m(model, task, extension, add_local_measures, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Execute runs in parallel\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# assuming the same number of tasks as workers (n_jobs), the total compute time for this\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# statement will be similar to the slowest run\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# TODO(eddiebergman): Simplify this\u001b[39;00m\n\u001b[1;32m    545\u001b[0m job_rvals: \u001b[38;5;28mlist\u001b[39m[\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mtuple\u001b[39m[\n\u001b[1;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m     ],\n\u001b[1;32m    554\u001b[0m ]\n\u001b[0;32m--> 555\u001b[0m job_rvals \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_task_get_arffcontent_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_n_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjobs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# job_rvals contain the output of all the runs with one-to-one correspondence with `jobs`\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_fit, rep_no, fold_no, sample_no \u001b[38;5;129;01min\u001b[39;00m jobs:\n\u001b[1;32m    570\u001b[0m     pred_y, proba_y, test_indices, test_y, inner_trace, user_defined_measures_fold \u001b[38;5;241m=\u001b[39m job_rvals[\n\u001b[1;32m    571\u001b[0m         n_fit \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    572\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:792\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent_parallel_helper\u001b[0;34m(extension, fold_no, model, rep_no, sample_no, task, dataset_format, configuration)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(task\u001b[38;5;241m.\u001b[39mtask_type)\n\u001b[1;32m    782\u001b[0m config\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing to run model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopenml\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mget_dataset(task\u001b[38;5;241m.\u001b[39mdataset_id)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor repeat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    787\u001b[0m (\n\u001b[1;32m    788\u001b[0m     pred_y,\n\u001b[1;32m    789\u001b[0m     proba_y,\n\u001b[1;32m    790\u001b[0m     user_defined_measures_fold,\n\u001b[1;32m    791\u001b[0m     trace,\n\u001b[0;32m--> 792\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mextension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(eddiebergman): Likely should not be ignored\u001b[39;49;00m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_y, proba_y, test_indices, test_y, trace, user_defined_measures_fold\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/extension.py:1120\u001b[0m, in \u001b[0;36mPytorchExtension._run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer not set to config. Please use openml_pytorch.config.trainer = trainer to set the trainer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1119\u001b[0m     )\n\u001b[0;32m-> 1120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:560\u001b[0m, in \u001b[0;36mOpenMLTrainerModule.run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m    556\u001b[0m     data, model_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_training(task, X_train, y_train, X_test)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;66;03m# typically happens when training a regressor8 on classification task\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyOpenMLError(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# In supervised learning this returns the predictions for Y\u001b[39;00m\n\u001b[1;32m    563\u001b[0m pred_y, proba_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_evaluation(task, data, model_classes)\n",
      "\u001b[0;31mPyOpenMLError\u001b[0m: 'str' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet, Resnet50,1 epoch\",\n",
    "    data_module=data_module,\n",
    "    task_type= \"classification\",\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = openml_pytorch.add_experiment_info_to_run(run=run, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.cbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Transformer Image Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(362128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example model. You can do better :)\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer to the required number of classes\n",
    "num_classes = 200\n",
    "in_features = model.classifier[-1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features, num_classes),\n",
    ")\n",
    "\n",
    "# Optional: If you're fine-tuning, you may want to freeze the pre-trained layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # If you want to train the last layer only (the newly added layer)\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a custom Optimizer\n",
    "- If you want to use a custom optimizer, you can do so by defining the optimizer in the `optimizer` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(362128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Choose a custom optimizer by defining the optimizer variable.\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam, Optimizer\n",
    "from openml_pytorch.trainer import OpenMLTask\n",
    "\n",
    "def custom_optimizer_gen(model: torch.nn.Module, task: OpenMLTask) -> Optimizer:\n",
    "    # replace the optimizer with your own\n",
    "    return Adam(model.fc.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    "    optimizer = custom_optimizer_gen,\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Classification Task\n",
    "- Sequential classification of a tabular MNIST dataset (Task 3573) using a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"dataframe\",\n",
    "    filename_col=\"class\",\n",
    "    target_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Download the OpenML task for the mnist 784 dataset.\n",
    "task = openml.tasks.get_task(3573)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################\n",
    "# Define a sequential network that does the initial image reshaping\n",
    "# and normalization model.\n",
    "processing_net = torch.nn.Sequential(\n",
    "    openml_pytorch.layers.Functional(function=torch.Tensor.reshape,\n",
    "                                                shape=(-1, 1, 28, 28)),\n",
    "    torch.nn.BatchNorm2d(num_features=1)\n",
    ")\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Define a sequential network that does the extracts the features from the\n",
    "# image.\n",
    "features_net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    ")\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Define a sequential network that flattens the features and compiles the\n",
    "# results into probabilities for each digit.\n",
    "results_net = torch.nn.Sequential(\n",
    "    openml_pytorch.layers.Functional(function=torch.Tensor.reshape,\n",
    "                                                shape=(-1, 4 * 4 * 64)),\n",
    "    torch.nn.Linear(in_features=4 * 4 * 64, out_features=256),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(in_features=256, out_features=10),\n",
    ")\n",
    "############################################################################\n",
    "# openml.config.apikey = 'key'\n",
    "\n",
    "############################################################################\n",
    "# The main network, composed of the above specified networks.\n",
    "model = torch.nn.Sequential(\n",
    "    processing_net,\n",
    "    features_net,\n",
    "    results_net\n",
    ")\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"MNIST\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular classification\n",
    "- Supervised credit-g classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"dataframe\",\n",
    "    target_column=\"class\",\n",
    "    target_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# supervised credit-g classification\n",
    "task = openml.tasks.get_task(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularClassificationmodel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TabularClassificationmodel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "model = TabularClassificationmodel(20, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Credit-G\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=5,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmlpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
