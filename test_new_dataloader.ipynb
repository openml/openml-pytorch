{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/openml_pytorch-0.0.6-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/torchvision-0.15.0-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/torchvision-0.16.0-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/torchvision-0.17.0-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openml-pytorch in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/openml_pytorch-0.0.6-py3.11.egg (0.0.6)\n",
      "Requirement already satisfied: openml in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml-pytorch) (0.15.1)\n",
      "Collecting torch<2.2.0,>=1.4.0 (from openml-pytorch)\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: onnx in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml-pytorch) (1.17.0)\n",
      "Requirement already satisfied: torchvision in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages/torchvision-0.17.0-py3.11-macosx-14.5-arm64.egg (from openml-pytorch) (0.17.0)\n",
      "Requirement already satisfied: filelock in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torch<2.2.0,>=1.4.0->openml-pytorch) (2025.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from onnx->openml-pytorch) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from onnx->openml-pytorch) (5.29.3)\n",
      "Requirement already satisfied: liac-arff>=2.4.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (2.5.0)\n",
      "Requirement already satisfied: xmltodict in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (0.14.2)\n",
      "Requirement already satisfied: requests in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (1.6.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (2.2.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (1.15.1)\n",
      "Requirement already satisfied: minio in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (7.2.15)\n",
      "Requirement already satisfied: pyarrow in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (19.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (4.67.1)\n",
      "Requirement already satisfied: packaging in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from openml->openml-pytorch) (24.2)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from openml-pytorch)\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "  Downloading torchvision-0.19.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "  Downloading torchvision-0.18.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "  Downloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from torchvision->openml-pytorch) (11.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from pandas>=1.0.0->openml->openml-pytorch) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from pandas>=1.0.0->openml->openml-pytorch) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from python-dateutil->openml->openml-pytorch) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from scikit-learn>=0.18->openml->openml-pytorch) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from scikit-learn>=0.18->openml->openml-pytorch) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from jinja2->torch<2.2.0,>=1.4.0->openml-pytorch) (3.0.2)\n",
      "Requirement already satisfied: certifi in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from minio->openml->openml-pytorch) (2025.1.31)\n",
      "Requirement already satisfied: urllib3 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from minio->openml->openml-pytorch) (2.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from minio->openml->openml-pytorch) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from minio->openml->openml-pytorch) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from requests->openml->openml-pytorch) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from requests->openml->openml-pytorch) (3.10)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from sympy->torch<2.2.0,>=1.4.0->openml-pytorch) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from argon2-cffi->minio->openml->openml-pytorch) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml->openml-pytorch) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/smukherjee/.pyenv/versions/3.11.9/envs/openmlpytorch/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml->openml-pytorch) (2.22)\n",
      "Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.2.0 requires torch==2.2.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.2 torchvision-0.16.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openml-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:01:33.514283Z",
     "start_time": "2024-09-23T12:01:32.116044Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smukherjee/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "# openml.config.start_using_configuration_for_example()\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:01:39.788930Z",
     "start_time": "2024-09-23T12:01:34.041129Z"
    }
   },
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(363295)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Classification Task\n",
       "==========================\n",
       "Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION\n",
       "Task ID..............: 363295\n",
       "Task URL.............: https://www.openml.org/t/363295\n",
       "Estimation Procedure.: crossvalidation\n",
       "Evaluation Measure...: predictive_accuracy\n",
       "Target Feature.......: label\n",
       "# of Classes.........: 200\n",
       "Cost Matrix..........: Available"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss tensor(5.3882, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m OpenMLTrainerModule(\n\u001b[1;32m      2\u001b[0m     experiment_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiny ImageNet, Resnet50,1 epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     data_module\u001b[38;5;241m=\u001b[39mdata_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ],\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m openml_pytorch\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m---> 13\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mopenml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:164\u001b[0m, in \u001b[0;36mrun_model_on_task\u001b[0;34m(model, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, return_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _task\n\u001b[1;32m    162\u001b[0m task \u001b[38;5;241m=\u001b[39m get_task_and_type_conversion(task)\n\u001b[0;32m--> 164\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mrun_flow_on_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavoid_duplicate_runs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflow_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupload_flow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupload_flow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_flow:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run, flow\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:302\u001b[0m, in \u001b[0;36mrun_flow_on_task\u001b[0;34m(flow, task, avoid_duplicate_runs, flow_tags, seed, add_local_measures, upload_flow, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is already fitted!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This might cause inconsistency in comparison of results.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# execute the run\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43m_run_task_get_arffcontent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_local_measures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_local_measures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m data_content, trace, fold_evaluations, sample_evaluations \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    312\u001b[0m fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mrun_environment, time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%c\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated by run_flow_on_task\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:555\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent\u001b[0;34m(model, task, extension, add_local_measures, dataset_format, n_jobs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Execute runs in parallel\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;66;03m# assuming the same number of tasks as workers (n_jobs), the total compute time for this\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# statement will be similar to the slowest run\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# TODO(eddiebergman): Simplify this\u001b[39;00m\n\u001b[1;32m    545\u001b[0m job_rvals: \u001b[38;5;28mlist\u001b[39m[\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28mtuple\u001b[39m[\n\u001b[1;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m     ],\n\u001b[1;32m    554\u001b[0m ]\n\u001b[0;32m--> 555\u001b[0m job_rvals \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_task_get_arffcontent_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_n_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_no\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjobs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# job_rvals contain the output of all the runs with one-to-one correspondence with `jobs`\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_fit, rep_no, fold_no, sample_no \u001b[38;5;129;01min\u001b[39;00m jobs:\n\u001b[1;32m    570\u001b[0m     pred_y, proba_y, test_indices, test_y, inner_trace, user_defined_measures_fold \u001b[38;5;241m=\u001b[39m job_rvals[\n\u001b[1;32m    571\u001b[0m         n_fit \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    572\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/openml/runs/functions.py:792\u001b[0m, in \u001b[0;36m_run_task_get_arffcontent_parallel_helper\u001b[0;34m(extension, fold_no, model, rep_no, sample_no, task, dataset_format, configuration)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(task\u001b[38;5;241m.\u001b[39mtask_type)\n\u001b[1;32m    782\u001b[0m config\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing to run model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopenml\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mget_dataset(task\u001b[38;5;241m.\u001b[39mdataset_id)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor repeat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrep_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    786\u001b[0m )\n\u001b[1;32m    787\u001b[0m (\n\u001b[1;32m    788\u001b[0m     pred_y,\n\u001b[1;32m    789\u001b[0m     proba_y,\n\u001b[1;32m    790\u001b[0m     user_defined_measures_fold,\n\u001b[1;32m    791\u001b[0m     trace,\n\u001b[0;32m--> 792\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mextension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(eddiebergman): Likely should not be ignored\u001b[39;49;00m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred_y, proba_y, test_indices, test_y, trace, user_defined_measures_fold\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/extension.py:1120\u001b[0m, in \u001b[0;36mPytorchExtension._run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer not set to config. Please use openml_pytorch.config.trainer = trainer to set the trainer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1119\u001b[0m     )\n\u001b[0;32m-> 1120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model_on_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:644\u001b[0m, in \u001b[0;36mOpenMLTrainerModule.run_model_on_fold\u001b[0;34m(self, model, task, X_train, rep_no, fold_no, y_train, X_test)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     data, model_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# typically happens when training a regressor8 on classification task\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PyOpenMLError(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:791\u001b[0m, in \u001b[0;36mOpenMLTrainerModule.run_training\u001b[0;34m(self, task, X_train, y_train, X_test)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_classes \u001b[38;5;241m=\u001b[39m model_classes\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mcbs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlrs\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:491\u001b[0m, in \u001b[0;36mModelRunner.fit\u001b[0;34m(self, epochs, learn)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 491\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin_validate\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:478\u001b[0m, in \u001b[0;36mModelRunner.all_batches\u001b[0;34m(self, dl)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m tqdm(dl, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 478\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CancelEpochException:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter_cancel_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:454\u001b[0m, in \u001b[0;36mModelRunner.one_batch\u001b[0;34m(self, xb, yb)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb \u001b[38;5;241m=\u001b[39m xb, yb\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# Below two lines are hack to convert model to onnx\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m sample_input\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/trainer.py:505\u001b[0m, in \u001b[0;36mModelRunner.__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m    503\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39m_order):\n\u001b[0;32m--> 505\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m res\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/callbacks/callback.py:28\u001b[0m, in \u001b[0;36mCallback.__call__\u001b[0;34m(self, cb_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cb_name):\n\u001b[1;32m     27\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, cb_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CODE/Github/openml-pytorch/openml_pytorch/callbacks/tensorboard.py:14\u001b[0m, in \u001b[0;36mTensorBoardCallback.begin_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbegin_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_graph:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/tensorboard/writer.py:873\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    869\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[0;32m--> 873\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m     )\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/tensorboard/_pytorch_graph.py:335\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[1;32m    337\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/jit/_trace.py:798\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m ):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/jit/_trace.py:1093\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m                 _check_trace(\n\u001b[1;32m   1082\u001b[0m                     check_inputs,\n\u001b[1;32m   1083\u001b[0m                     func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1090\u001b[0m                     example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39mexample_inputs_is_kwarg,\n\u001b[1;32m   1091\u001b[0m                 )\n\u001b[1;32m   1092\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1093\u001b[0m                 \u001b[43m_check_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_trace_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m old_module_map\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/jit/_trace.py:563\u001b[0m, in \u001b[0;36m_check_trace\u001b[0;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class, example_inputs_is_kwarg)\u001b[0m\n\u001b[1;32m    561\u001b[0m traced_outs \u001b[38;5;241m=\u001b[39m run_mod_and_filter_tensor_outputs(traced_func, inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m fn_outs \u001b[38;5;241m=\u001b[39m run_mod_and_filter_tensor_outputs(func, inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcompare_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraced_outs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_outs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPython function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    564\u001b[0m     check_outs \u001b[38;5;241m=\u001b[39m run_mod_and_filter_tensor_outputs(\n\u001b[1;32m    565\u001b[0m         check_mod_func, inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepeated trace\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m     compare_outputs(traced_outs, check_outs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepeated trace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/jit/_trace.py:529\u001b[0m, in \u001b[0;36m_check_trace.<locals>.compare_outputs\u001b[0;34m(original, reference, match_what)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig\u001b[38;5;241m.\u001b[39mis_mps \u001b[38;5;129;01mor\u001b[39;00m ref\u001b[38;5;241m.\u001b[39mis_mps:\n\u001b[0;32m--> 529\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[43morig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m            \u001b[49m\u001b[43mref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m            \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_tolerances\u001b[49m\u001b[43m(\u001b[49m\u001b[43morig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m            \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    537\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_close(\n\u001b[1;32m    538\u001b[0m             orig\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m    539\u001b[0m             ref\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    542\u001b[0m             equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    543\u001b[0m         )\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/testing/_comparison.py:712\u001b[0m, in \u001b[0;36mTensorLikePair.compare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (actual, expected)):\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 712\u001b[0m actual, expected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_equalize_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compare_values(actual, expected)\n",
      "File \u001b[0;32m~/.pyenv/versions/openmlpytorch/lib/python3.11/site-packages/torch/testing/_comparison.py:795\u001b[0m, in \u001b[0;36mTensorLikePair._equalize_attributes\u001b[0;34m(self, actual, expected)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# The comparison logic uses operators currently not supported by the MPS backends.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m#  See https://github.com/pytorch/pytorch/issues/77144 for details.\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# TODO: Remove this conversion as soon as all operations are supported natively by the MPS backend\u001b[39;00m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual\u001b[38;5;241m.\u001b[39mis_mps \u001b[38;5;129;01mor\u001b[39;00m expected\u001b[38;5;241m.\u001b[39mis_mps:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m     actual \u001b[38;5;241m=\u001b[39m \u001b[43mactual\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     expected \u001b[38;5;241m=\u001b[39m expected\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m expected\u001b[38;5;241m.\u001b[39mdevice:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet, Resnet50,1 epoch\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing push\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = openml_pytorch.add_experiment_info_to_run(run=run, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.cbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Transformer Image Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(362128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example model. You can do better :)\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modify the last fully connected layer to the required number of classes\n",
    "num_classes = 200\n",
    "in_features = model.classifier[-1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features, num_classes),\n",
    ")\n",
    "\n",
    "# Optional: If you're fine-tuning, you may want to freeze the pre-trained layers\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # If you want to train the last layer only (the newly added layer)\n",
    "# for param in model.fc.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a custom Optimizer\n",
    "- If you want to use a custom optimizer, you can do so by defining the optimizer in the `optimizer` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from torchvision.transforms import Compose, Resize, ToPILImage, ToTensor, Lambda\n",
    "import torchvision\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "        ToPILImage(),  # Convert tensor to PIL Image to ensure PIL Image operations can be applied.\n",
    "        Lambda(convert_to_rgb),  # Convert PIL Image to RGB if it's not already.\n",
    "        Resize((64, 64)),  # Resize the image.\n",
    "        ToTensor(),  # Convert the PIL Image back to a tensor.\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"image\",\n",
    "    file_dir=\"datasets\",\n",
    "    filename_col=\"image_path\",\n",
    "    target_mode=\"categorical\",\n",
    "    target_column=\"label\",\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Download the OpenML task for tiniest imagenet\n",
    "task = openml.tasks.get_task(362128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(num_classes=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Choose a custom optimizer by defining the optimizer variable.\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam, Optimizer\n",
    "from openml_pytorch.trainer import OpenMLTask\n",
    "\n",
    "def custom_optimizer_gen(model: torch.nn.Module, task: OpenMLTask) -> Optimizer:\n",
    "    # replace the optimizer with your own\n",
    "    return Adam(model.fc.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Tiny ImageNet\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    "    optimizer = custom_optimizer_gen,\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Classification Task\n",
    "- Sequential classification of a tabular MNIST dataset (Task 3573) using a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"dataframe\",\n",
    "    filename_col=\"class\",\n",
    "    target_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# Download the OpenML task for the mnist 784 dataset.\n",
    "task = openml.tasks.get_task(3573)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################################\n",
    "# Define a sequential network that does the initial image reshaping\n",
    "# and normalization model.\n",
    "processing_net = torch.nn.Sequential(\n",
    "    openml_pytorch.layers.Functional(function=torch.Tensor.reshape,\n",
    "                                                shape=(-1, 1, 28, 28)),\n",
    "    torch.nn.BatchNorm2d(num_features=1)\n",
    ")\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Define a sequential network that does the extracts the features from the\n",
    "# image.\n",
    "features_net = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    "    torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2),\n",
    ")\n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "# Define a sequential network that flattens the features and compiles the\n",
    "# results into probabilities for each digit.\n",
    "results_net = torch.nn.Sequential(\n",
    "    openml_pytorch.layers.Functional(function=torch.Tensor.reshape,\n",
    "                                                shape=(-1, 4 * 4 * 64)),\n",
    "    torch.nn.Linear(in_features=4 * 4 * 64, out_features=256),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Dropout(),\n",
    "    torch.nn.Linear(in_features=256, out_features=10),\n",
    ")\n",
    "############################################################################\n",
    "# openml.config.apikey = 'key'\n",
    "\n",
    "############################################################################\n",
    "# The main network, composed of the above specified networks.\n",
    "model = torch.nn.Sequential(\n",
    "    processing_net,\n",
    "    features_net,\n",
    "    results_net\n",
    ")\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"MNIST\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=1,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular classification\n",
    "- Supervised credit-g classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openml imports\n",
    "import openml\n",
    "import openml_pytorch\n",
    "from openml_pytorch.callbacks import TestCallback\n",
    "from openml_pytorch.metrics import accuracy\n",
    "from openml_pytorch.trainer import OpenMLDataModule, OpenMLTrainerModule, convert_to_rgb\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "\n",
    "# other imports\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# set up logging\n",
    "openml.config.logger.setLevel(logging.DEBUG)\n",
    "openml_pytorch.config.logger.setLevel(logging.DEBUG)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Data Module and Choose a Task\n",
    "- Make sure the data is present in the `file_dir` directory, and the `filename_col` is correctly set along with this column correctly pointing to where your data is stored. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = OpenMLDataModule(\n",
    "    type_of_data=\"dataframe\",\n",
    "    target_column=\"class\",\n",
    "    target_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "# supervised credit-g classification\n",
    "task = openml.tasks.get_task(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularClassificationmodel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(TabularClassificationmodel, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, output_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "model = TabularClassificationmodel(20, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model on the data\n",
    "- Note that by default, OpenML runs a 10 fold cross validation on the data. You cannot change this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = OpenMLTrainerModule(\n",
    "    experiment_name= \"Credit-G\",\n",
    "    data_module=data_module,\n",
    "    verbose=True,\n",
    "    epoch_count=5,\n",
    "    metrics= [accuracy],\n",
    "    # remove the TestCallback when you are done testing your pipeline. Having it here will make the pipeline run for a very short time.\n",
    "    callbacks=[\n",
    "        TestCallback,\n",
    "    ],\n",
    ")\n",
    "openml_pytorch.config.trainer = trainer\n",
    "run = openml.runs.run_model_on_task(model, task, avoid_duplicate_runs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View information about your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate and loss plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Vizualization\n",
    "- Sometimes you may want to visualize the model. You can either use netron or tensorboard for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.export_to_netron()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- By default, openml will log the tensorboard logs in the `tensorboard_logs` directory. You can view the logs by running `tensorboard --logdir tensorboard_logs` in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish your model to OpenML\n",
    "- This is Optional, but publishing your model to OpenML will allow you to track your experiments and compare them with others.\n",
    "- Make sure to set your apikey first.\n",
    "  - You can find your apikey on your OpenML account page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.apikey = ''\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmlpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
